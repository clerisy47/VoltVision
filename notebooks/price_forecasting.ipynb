{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price Forecasting: Time Series Analysis and Model Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1. Problem Statement\n",
    "The energy industry is undergoing a transformative journey, marked by rapid modernization and technological advancements. Infrastructure upgrades, integration of intermittent renewable energy sources, and evolving consumer demands are reshaping the sector. However, this progress comes with its challenges. Supply, demand, and prices are increasingly volatile, rendering the future less predictable. Moreover, the industry's traditional business models are being fundamentally challenged. In this competitive and dynamic landscape, accurate decision-making is pivotal. The industry relies heavily on probabilistic forecasts to navigate this uncertain future, making innovative and precise forecasting methods essential that aids stakeholders in making strategic decisions amidst the shifting energy landscape. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Zenml-MLfow pipeline for Data Ingestion](../steps/price_forecasting/data_ingestion.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Import Data and Required Packages\n",
    "Importing Pandas, Numpy, Matplotlib,Scipy and Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Import the CSV Data as Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price = pd.read_csv('../dataset/Price forecasting/Price Forecasting data upto December 24.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Zenml-MLfow pipeline for Data Preprocessing](../steps/price_forecasting/data_preprocessing.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Show top 5 records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Shape of Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Dataset Information\n",
    "<li>Delivery Day: Represents date</li>\n",
    "<li>Hours: Represents Specific Hour of Day</li>\n",
    "<li>Prices\\n(Eur/MWh): Represents price of electricity in Euro per megawatt of electricity</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Dealing with missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping rows having values NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price.dropna(how='all', inplace=True)\n",
    "df_price.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 Dealing with Inconsistent Datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>From descriptive statistics analysis, minimum value of price is found to be negative which concludes there are some negative values of price which makes no sense.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Checking For Negative or Zero Prices</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price[df_price['Prices\\n(EUR/MWh)']<=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Replacing Negative or Zero Prices with NaN</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_price['Prices\\n(EUR/MWh)'] <= 0\n",
    "df_price.loc[mask, 'Prices\\n(EUR/MWh)'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Using linear interpolation to fill NaN Values</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price['Prices\\n(EUR/MWh)'].interpolate(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7 Removing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zscore = scipy.stats.zscore(df_price['Prices\\n(EUR/MWh)'])\n",
    "df_price = df_price[abs(zscore)<5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Datetime Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Merging Delivery day and Hours columns as Datetime to create date time object</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeMap = {\n",
    "    f'H{i+1}': f'{i:02d}' for i in range(0, 24)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price.loc[:, \"Time\"] = df_price[\"Hours\"].apply(lambda x: timeMap[x] + \":00:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price.loc[:, 'Datetime'] = df_price['Delivery Day'] + ' ' + df_price['Time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Changing data type of Datetime values to Timestamp</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price.loc[:, 'Datetime'] = pd.to_datetime(df_price['Datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Making Datetime Column as index</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price.set_index('Datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Dropping Time Column</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price.drop('Time', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Visualizing Datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Time Series analysis of Daily Price</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price['Prices\\n(EUR/MWh)'].resample('D').mean().plot()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Price (EUR/MWh)')\n",
    "plt.title('Daily Average Prices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Time Series Analysis of Weekly Price</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price['Prices\\n(EUR/MWh)'].resample('W').mean().plot()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Price (EUR/MWh)')\n",
    "plt.title('Weekly Average Prices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Time Series Analysis of Monthly Price</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price['Prices\\n(EUR/MWh)'].resample('M').mean().plot()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Price (EUR/MWh)')\n",
    "plt.title('Monthly Average Prices')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Average Prices of electricity for each hour of day</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_order = [f'H{i}' for i in range(1, 25)] \n",
    "\n",
    "# Group by the 'Hours' column and calculate the mean for each group\n",
    "hourly_average = df_price.groupby('Hours')['Prices\\n(EUR/MWh)'].mean()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot a bar graph\n",
    "plt.bar(hour_order, hourly_average.reindex(hour_order))\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('Average Price (EUR/MWh)')\n",
    "plt.title('Average Hourly Prices (Bar Graph)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Zenml-MLfow pipeline for Feature Engineering](../steps/price_forecasting/feature_engineering.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normalize continuous values and avoid vanishing gradient problems to finalize our data before model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df_price = scaler.fit_transform(df_price[\"Prices\\n(EUR/MWh)\"].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Train Validation Test Split\n",
    "- Splitting the data into different splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, train_size=0.8):\n",
    "    df_train = df[:int(train_size * len(df))]\n",
    "    df_test = df[int(train_size * len(df)):]\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Seperating dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = 15\n",
    "X_train, y_train = create_dataset(dataset=df_train, time_step=time_step)\n",
    "X_test, y_test = create_dataset(dataset=df_test, time_step=time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model Evaluation and Training\n",
    "#### [Zenml-MLfow pipeline for Model Evaluation](../steps/price_forecasting/model_evaluation.py)\n",
    "#### [Zenml-MLfow pipeline for Model Training](../steps/price_forecasting/training.py)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Making imports for Model Evaluation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Flatten, Dropout\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Model Training and Evaluation using XGBoost, LSTM, ARIMA and SARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2.1 XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGBoost model is configured with 1000 estimators and a learning rate of 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(n_estimators=1000, learning_rate=0.05)\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluation of XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pred = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, xgb_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2.2 LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The LSTM model is composed of an LSTM layer, followed by a dense layer with ReLU activation, a dropout layer, and a final dense layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(None, 1), return_sequences=True))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=200,batch_size=32,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training and Validation Loss Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "original_ytrain = scaler.inverse_transform(y_train.reshape(-1,1)) \n",
    "original_ytest = scaler.inverse_transform(y_test.reshape(-1,1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluation Metrics Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train data RMSE: \", math.sqrt(mean_squared_error(original_ytrain,train_predict)))\n",
    "print(\"Train data MSE: \", mean_squared_error(original_ytrain,train_predict))\n",
    "print(\"Train data MAE: \", mean_absolute_error(original_ytrain,train_predict))\n",
    "print(\"Test data RMSE: \", math.sqrt(mean_squared_error(original_ytest,test_predict)))\n",
    "print(\"Test data MSE: \", mean_squared_error(original_ytest,test_predict))\n",
    "print(\"Test data MAE: \", mean_absolute_error(original_ytest,test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2.3 ARIMA Model Order Selection\n",
    "This script performs an exhaustive search for the best ARIMA model order (p, d, q) based on the Akaike Information Criterion (AIC). It evaluates multiple combinations of p, d, and q values to find the model order that minimizes the AIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = [0, 1, 2]\n",
    "d_values = [0, 1]\n",
    "q_values = [0, 1, 2]\n",
    "pdq_combinations = [(p, d, q) for p in p_values for d in d_values for q in q_values]\n",
    "\n",
    "def evaluate_arima_models(data, pdq_combinations):\n",
    "    results = []\n",
    "    for pdq in pdq_combinations:\n",
    "        try:\n",
    "            model = ARIMA(data, order=pdq)\n",
    "            model_fit = model.fit()\n",
    "            aic = model_fit.aic\n",
    "            results.append((pdq, aic))\n",
    "        except:\n",
    "            continue\n",
    "    return results\n",
    "\n",
    "results = evaluate_arima_models(df_train, pdq_combinations)\n",
    "best_aic = min(results, key=lambda x: x[1])[1]\n",
    "best_pdq = [result[0] for result in results if result[1] == best_aic][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ARIMA Model Fitting and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best ARIMA parameters:\", best_pdq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(df_train, order=best_pdq)\n",
    "model_fit = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = model_fit.predict(start=len(df_train), end=len(df_price)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(df_test, df_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.4 Time Series  Analysis and Seasonal Differencing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_acf(df_train, lags=40) \n",
    "plot_pacf(df_train, lags=40)\n",
    "\n",
    "series_diff = pd.DataFrame(df_train).diff().dropna() \n",
    "\n",
    "plot_acf(series_diff, lags=40)\n",
    "plot_pacf(series_diff, lags=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KPSS Test for Seasonality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "potential_m_values = [7, 12, 24]  \n",
    "best_m = None\n",
    "best_kpss_stat = float('inf')\n",
    "\n",
    "for m in potential_m_values:\n",
    "    series_diff = pd.DataFrame(df_train).diff(m).dropna()\n",
    "\n",
    "    kpss_result = kpss(series_diff, regression='c')  \n",
    "    kpss_stat = kpss_result[0]\n",
    "    p_value = kpss_result[1]\n",
    "\n",
    "    if kpss_stat < best_kpss_stat and p_value > 0.05:\n",
    "        best_m = m\n",
    "        best_kpss_stat = kpss_stat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best m value based on KPSS test:\", best_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2.5 SARIMA Model Order Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The script iteratively fits SARIMA models with different seasonal order parameters and selects the configuration that minimizes the AIC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "seasonal_order_values = range(3) \n",
    "\n",
    "best_aic = np.inf\n",
    "best_seasonal_order = None\n",
    "\n",
    "for seasonal_order_candidate in itertools.product(seasonal_order_values, repeat=3):\n",
    "    p, d, q = (2, 1, 1)\n",
    "    P, D, Q = seasonal_order_candidate\n",
    "    m = 7 \n",
    "\n",
    "    sarima_model = sm.tsa.SARIMAX(df_train, order=(p, d, q), seasonal_order=(P, D, Q, m))\n",
    "    sarima_result = sarima_model.fit()\n",
    "\n",
    "    current_aic = sarima_result.aic\n",
    "\n",
    "    if current_aic < best_aic:\n",
    "        best_aic = current_aic\n",
    "        best_seasonal_order = (P, D, Q)\n",
    "\n",
    "print(\"Best Seasonal Order:\", best_seasonal_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima_model = sm.tsa.SARIMAX(df_train, order=(2, 1, 1), seasonal_order=(1, 0, 2, 7))\n",
    "sarima_result = sarima_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima_result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = sarima_result.predict(start=len(df_train), end=len(df_price)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 Evaluation\n",
    "- After fitting the SARIMA model and obtaining predictions on the test set (`df_test`), the script calculates the Mean Squared Error (MSE) as an evaluation metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(df_test, df_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Insight : SARIMA model performed the best and was finallized for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(xgb_model, '../model/price_forecasting.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
